# -*- coding: utf-8 -*-
"""Subtask A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hYoX_kmC15_w5X4W5nz48VsJSzmJVkxK

# "SemEval-2026 Task 13 Subtask A"

**(Detecting Machine-Generated Code - Binary Classification):**

**Objective:** Build models that can distinguish between human-written and AI-generated code, especially when the test data comes from different distributions (OOD).

**Challenge:** Traditional classifiers often overfit to training distributions. The competition pushes us to create detectors that remain reliable when faced with new languages, frameworks, or coding styles.

**Evaluation Metric:** F1 score, meaning you must balance precision (avoiding false positives) and recall (catching AI-generated code).

1. Setup & Imports
"""

# Core libraries
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# ML
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, f1_score

# Transformers
from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, Trainer, TrainingArguments

# Visualization style
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (8, 5)

"""2. Load the dataset"""

train = pd.read_parquet("train.parquet")
validation = pd.read_parquet("validation.parquet")
test = pd.read_parquet("test.parquet")

"""| column        | meaning                               |
| ------------- | ------------------------------------- |
| **code**      | the source code snippet (string)      |
| **generator** | which model generated it OR `'human'` |
| **language**  | programming language (Python/JS/etc.) |
| **label**     | 0 = human-written, 1 = AI-generated   |

# 3. Explatory Data analysis
"""

#a quick overview of the columns, dtypes, and sizes of each split.

print("=== Shapes ===")
print("Train shape      :", train.shape)
print("Validation shape :", validation.shape)
print("Test shape       :", test.shape)


print("\n=== Train Info ===")
train.info()

print("\n=== First 5 rows of train ===")
display(train.head())

#Quick schema / column names check

print("Train columns      :", train.columns.tolist())
print("Validation columns :", validation.columns.tolist())
print("Test columns       :", test.columns.tolist())

#Check missing values

def missing_values_report(df, name="df"):
    print(f"Missing values in {name}:")
    display(df.isna().sum())
    print("-" * 40)

missing_values_report(train, "train")
missing_values_report(validation, "validation")
missing_values_report(test, "test")

#Basic descriptive statistics for non-text columns

print("Train describe (numeric columns):")
display(train.describe(include=[np.number]))

print("\nTrain describe (all columns):")
display(train.describe(include="all"))

"""Label distribution (train vs validation vs test_sample)"""

#Explore class balance; very important for modeling and baseline choice.

# Train label distribution
print("Train label counts:")
display(train['label'].value_counts())

print("\nTrain label percentages:")
display(train['label'].value_counts(normalize=True) * 100)

# Validation label distribution (if labeled)
if 'label' in validation.columns:
    print("\nValidation label counts:")
    display(validation['label'].value_counts())
    print("\nValidation label percentages:")
    display(validation['label'].value_counts(normalize=True) * 100)

#Plot label distribution for train

#Visual inspection of balance between human (0) and AI (1).

sns.countplot(data=train, x='label')
plt.title("Label Distribution in Train (0 = Human, 1 = AI)")
plt.xlabel("Label")
plt.ylabel("Count")
plt.show()

#Generator distribution

#See which generators appear and how frequent they are.

plt.figure(figsize=(10, 5))
train['generator'].value_counts().plot(kind='bar')
plt.title("Generator Distribution in Train")
plt.xlabel("Generator (model or 'human')")
plt.ylabel("Count")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

print("Generator value counts:")
display(train['generator'].value_counts())

#Language distribution

#Understand the programming languages present and their frequencies.

plt.figure(figsize=(10, 6))
sns.barplot(x=train['language'].value_counts().index, y=train['language'].value_counts().values, hue=train['language'].value_counts().index, palette='viridis', legend=False)
plt.title("Subtask A Distribution of Languages in Training Data")
plt.xlabel("Language")
plt.ylabel("Count")
plt.xticks(rotation=45, ha='right') # Rotate x-axis labels
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

print("Language value counts:")
display(train['language'].value_counts())

#Compare language distributions across splits

#Check if train/validation/test have similar language proportions (dataset shift).

def value_pct(df, col, name):
    vc = df[col].value_counts(normalize=True) * 100
    print(f"{name} – {col} distribution (%):")
    display(vc)
    print("-" * 40)

value_pct(train, 'language', 'Train')
value_pct(validation, 'language', 'Validation')

#Create code length features

#These are very informative features (AI vs human often differ in length/structure).

# Character length
train['code_len_chars'] = train['code'].str.len()
validation['code_len_chars'] = validation['code'].str.len()
test['code_len_chars'] = test['code'].str.len()

# Number of lines
train['code_len_lines'] = train['code'].apply(lambda x: len(str(x).split('\n')))
validation['code_len_lines'] = validation['code'].apply(lambda x: len(str(x).split('\n')))
test['code_len_lines'] = test['code'].apply(lambda x: len(str(x).split('\n')))

# Optional: rough token count (split by whitespace)
train['code_len_tokens'] = train['code'].apply(lambda x: len(str(x).split()))
validation['code_len_tokens'] = validation['code'].apply(lambda x: len(str(x).split()))
test['code_len_tokens'] = test['code'].apply(lambda x: len(str(x).split()))

train[['code_len_chars', 'code_len_lines', 'code_len_tokens']].describe()

#Histograms for code length (train)

#See distribution of code sizes.

# Compute percentiles
p99_chars = train['code_len_chars'].quantile(0.99)
p99_lines = train['code_len_lines'].quantile(0.99)
p99_tokens = train['code_len_tokens'].quantile(0.99)

# Plot 1: Code Length (characters)
plt.figure(figsize=(10, 6))
sns.histplot(train[train['code_len_chars'] < p99_chars]['code_len_chars'], bins=50, kde=True, color='skyblue')
plt.title("Subtask A Code Length Distribution (Characters) ")
plt.xlabel("Code Length (characters)")
plt.ylabel("Count / Density")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Plot 2: Code Length (lines)
plt.figure(figsize=(10, 6))
sns.histplot(train[train['code_len_lines'] < p99_lines]['code_len_lines'], bins=50, kde=True, color='lightcoral')
plt.title("Subtask A Code Length Distribution (Lines) ")
plt.xlabel("Code Length (lines)")
plt.ylabel("Count / Density")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Plot 3: Code Length (tokens)
plt.figure(figsize=(10, 6))
sns.histplot(train[train['code_len_tokens'] < p99_tokens]['code_len_tokens'], bins=50, kde=True, color='lightgreen')
plt.title("Subtask A Code Length Distribution (Tokens) ")
plt.xlabel("Code Length (tokens)")
plt.ylabel("Count / Density")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

#Code length by label (AI vs Human)

#Check if AI vs human code differ in length.

# Compute 99th percentiles
p99_chars = train['code_len_chars'].quantile(0.99)
p99_lines = train['code_len_lines'].quantile(0.99)
p99_tokens = train['code_len_tokens'].quantile(0.99)

# Filter dataset
filtered = train[
    (train['code_len_chars'] < p99_chars) &
    (train['code_len_lines'] < p99_lines) &
    (train['code_len_tokens'] < p99_tokens)
].copy() # Use .copy() to avoid SettingWithCopyWarning

# Convert 'label' to string type for palette to work correctly with numeric x-axis values
filtered['label'] = filtered['label'].astype(str)

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

sns.boxplot(data=filtered, x='label', y='code_len_chars', ax=axes[0], hue='label', palette={'0': 'skyblue', '1': 'salmon'}, legend=False)
axes[0].set_title("Subtask A Code Length (characters) by Label")
axes[0].set_xlabel("Label (0=Human, 1=AI)")
axes[0].set_ylabel("Code Length (characters)")
axes[0].grid(axis='y', linestyle='--', alpha=0.7)

sns.boxplot(data=filtered, x='label', y='code_len_lines', ax=axes[1], hue='label', palette={'0': 'skyblue', '1': 'salmon'}, legend=False)
axes[1].set_title("Subtask A Code Length (lines) by Label")
axes[1].set_xlabel("Label (0=Human, 1=AI)")
axes[1].set_ylabel("Code Length (lines)")
axes[1].grid(axis='y', linestyle='--', alpha=0.7)

sns.boxplot(data=filtered, x='label', y='code_len_tokens', ax=axes[2], hue='label', palette={'0': 'skyblue', '1': 'salmon'}, legend=False)
axes[2].set_title("Subtask A Code Length (tokens) by Label")
axes[2].set_xlabel("Label (0=Human, 1=AI)")
axes[2].set_ylabel("Code Length (tokens)")
axes[2].grid(axis='y', linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

#Generator × Label relationship

#See which generators correspond to which labels (some might be always AI).

gen_label_ct = pd.crosstab(train['generator'], train['label'])
print("Generator vs Label (counts):")
display(gen_label_ct)

print("\nGenerator vs Label (row-wise percentages):")
display(gen_label_ct.div(gen_label_ct.sum(axis=1), axis=0) * 100)

cross_tab = pd.crosstab(train['generator'], train['label'])

plt.figure(figsize=(12, 8))
sns.heatmap(
    cross_tab,
    annot=True,
    fmt="d",
    cmap="viridis",
    linewidths=.5,
    linecolor='black'
)
plt.title("Generator vs. Label Relationship (Counts)")
plt.xlabel("Label ID")
plt.ylabel("Generator")
plt.tight_layout()
plt.show()

#Language × Label relationship

#Check if some languages are more often AI vs human.

lang_label_ct = pd.crosstab(train['language'], train['label'])
print("Language vs Label (counts):")
display(lang_label_ct)

print("\nLanguage vs Label (row-wise percentages):")
display(lang_label_ct.div(lang_label_ct.sum(axis=1), axis=0) * 100)

#Quick qualitative peek: sample human vs AI code

#Helps you get an intuition for stylistic differences.

print("=== Example human code (label=0) ===")
display(train[train['label'] == 0].sample(1, random_state=42)[['language', 'generator', 'code']])

print("\n=== Example AI-generated code (label=1) ===")
display(train[train['label'] == 1].sample(1, random_state=42)[['language', 'generator', 'code']])

"""# Simple baseline model

We’ll build a TF-IDF (char n-grams) + Logistic Regression model that:

uses only code as input (no generator leakage )

trains on train.parquet

evaluates on validation.parquet

predicts on test.parquet and writes a Kaggle submission CSV
"""

#Extra imports for baseline

# Feature extraction
from sklearn.feature_extraction.text import TfidfVectorizer

# Pipeline & model
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

# Metrics
from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score

"""Define X and Y for train and validation

Note: We use:

code as the input text

label as the target

We do not use generator to avoid label leakage.
"""

# Features and labels
X_train = train["code"].astype(str).values
y_train = train["label"].values

X_val = validation["code"].astype(str).values
y_val = validation["label"].values

print("Train samples:", len(X_train))
print("Validation samples:", len(X_val))

#Build TF-IDF + Logistic Regression pipeline

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# Optional: handle slight imbalance via class weights
classes = np.unique(y_train)
class_weights = compute_class_weight(class_weight="balanced", classes=classes, y=y_train)
class_weight_dict = {cls: w for cls, w in zip(classes, class_weights)}
print("Class weights:", class_weight_dict)

baseline_clf = Pipeline([
    ("tfidf", TfidfVectorizer(
        analyzer="char",          # character n-grams
        ngram_range=(3, 5),       # 3-5 char n-grams
        min_df=5,                 # ignore very rare n-grams
        max_features=200_000,     # adjust based on RAM
    )),
    ("logreg", LogisticRegression(
        max_iter=1000,
        n_jobs=-1,
        class_weight=class_weight_dict,
        solver="lbfgs"
    ))
])

"""**Train the baseline model**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# baseline_clf.fit(X_train, y_train)
#

"""**Evaluate on validation set**

We compute:

- Accuracy (implicit from classification report)

- F1-score

- ROC-AUC

- Confusion matrix
"""

# Predictions
y_val_pred = baseline_clf.predict(X_val)
y_val_proba = baseline_clf.predict_proba(X_val)[:, 1]

print("=== Classification report (Validation) ===")
print(classification_report(y_val, y_val_pred, digits=4))

print("=== F1-score (macro) ===")
print(f1_score(y_val, y_val_pred, average="macro"))

print("=== ROC-AUC ===")
print(roc_auc_score(y_val, y_val_proba))

print("=== Confusion Matrix ===")
print(confusion_matrix(y_val, y_val_pred))

#Confusion Matrix Heatmap

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_val, y_val_pred)
class_names = ["Human (0)", "Machine (1)"]

plt.figure(figsize=(5,4))
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    xticklabels=class_names,
    yticklabels=class_names
)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("TF–IDF + Logistic Regression\nConfusion Matrix (Validation)")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    precision_score,
    recall_score,
    roc_auc_score
)

accuracy = accuracy_score(y_val, y_val_pred)
macro_f1 = f1_score(y_val, y_val_pred, average="macro")
macro_precision = precision_score(y_val, y_val_pred, average="macro")
macro_recall = recall_score(y_val, y_val_pred, average="macro")
roc_auc = roc_auc_score(y_val, y_val_proba)

metric_names = ["Macro F1", "Accuracy", "Macro Precision", "Macro Recall", "ROC–AUC"]
metric_values = [macro_f1, accuracy, macro_precision, macro_recall, roc_auc]

plt.figure(figsize=(8,5))
barplot = sns.barplot(x=metric_names, y=metric_values, hue=metric_names, palette="viridis", legend=False)
plt.ylim(0.9, 1.0)  # adjust if needed
plt.ylabel("Score")
plt.title("TF–IDF + Logistic Regression\nOverall Evaluation Metrics (Validation)")
plt.xticks(rotation=30, ha="right")

# Add value annotations on top of each bar
for index, value in enumerate(metric_values):
    barplot.text(index, value + 0.001, f'{value:.4f}', color='black', ha="center", va="bottom")

plt.grid(axis='y', linestyle='--', alpha=0.7) # Add a horizontal grid
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def binary_entropy(p):
    p = np.clip(p, 1e-12, 1 - 1e-12)
    return - (p * np.log2(p) + (1 - p) * np.log2(1 - p))

entropy_val = binary_entropy(y_val_proba)

plt.figure(figsize=(8,5))
sns.histplot(entropy_val, bins=50, kde=True, color='skyblue')
plt.xlabel("Entropy (bits)")
plt.ylabel("Count / Density")
plt.title("TF–IDF + Logistic Regression: Entropy Distribution (Validation Set)")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

#In-domain vs High-Entropy OOD

test_sample = pd.read_parquet("test_sample.parquet")  # OOD-ish set from SemEval
X_ood = test_sample["code"].astype(str).values

# Baseline probabilities on OOD
y_ood_proba = baseline_clf.predict_proba(X_ood)[:, 1]

entropy_ood = binary_entropy(y_ood_proba)

plt.figure(figsize=(8,6))
sns.kdeplot(entropy_val, fill=True, alpha=0.6, label="Validation (in-domain)", color='skyblue')
sns.kdeplot(entropy_ood, fill=True, alpha=0.6, label="OOD", color='salmon')
plt.xlabel("Entropy (bits)")
plt.ylabel("Density")
plt.title("TF–IDF + Logistic Regression: In-domain vs OOD Entropy Distribution")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

high_ood_mask = entropy_ood >= np.percentile(entropy_ood, 90)
high_entropy_ood = entropy_ood[high_ood_mask]

plt.figure(figsize=(8,6))
sns.kdeplot(entropy_val, fill=True, alpha=0.6, label="Validation (in-domain)", color='skyblue')
sns.kdeplot(high_entropy_ood, fill=True, alpha=0.6, label="High-entropy OOD (top 10%)", color='darkorange')
plt.xlabel("Entropy (bits)")
plt.ylabel("Density")
plt.title("TF–IDF + Logistic Regression: In-domain vs High-Entropy OOD Entropy Distribution")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""# Strong pipeline

**for OOD generalization (unseen languages + unseen domains), the best performing setup is NOT a single model, but a hybrid pipeline that combines:**

1. XGBoost captures style, structure, entropy, formatting, length, which
transfer well across languages.

2. CodeBERT/GraphCodeBERT captures semantic patterns and token structure.

3. The ensemble balances strengths and removes weaknesses.

This is the best-performing setup for unseen languages like Go, PHP, JS, C#, C and unseen domains.

**step 1: Feature Engineering for OOD Robustness**

We create language-agnostic features that generalize across unseen languages:
"""

import numpy as np
import re
from collections import Counter
import math

def calc_entropy(s):
    if not s:
        return 0.0
    probs = [freq/len(s) for freq in Counter(s).values()]
    return -sum(p * math.log2(p) for p in probs if p > 0)

def extract_features(code):
    lines = code.split("\n")
    num_lines = len(lines)
    num_chars = len(code)
    num_tokens = len(code.split())

    avg_line_len = num_chars / max(1, num_lines)
    line_lengths = [len(l) for l in lines]

    indent_levels = [len(re.match(r'\s*', l).group()) for l in lines]

    return {
        "num_chars": num_chars,
        "num_tokens": num_tokens,
        "num_lines": num_lines,
        "avg_line_len": avg_line_len,
        "line_len_var": np.var(line_lengths),
        "indent_var": np.var(indent_levels),
        "entropy": calc_entropy(code),

        # structural counts
        "brace_count": code.count("{") + code.count("}"),
        "paren_count": code.count("(") + code.count(")"),
        "bracket_count": code.count("[") + code.count("]"),
        "semicolon_count": code.count(";"),
        "comma_count": code.count(","),

        # keyword counts (works across most languages)
        "for_count": code.count("for"),
        "if_count": code.count("if"),
        "while_count": code.count("while"),
        "return_count": code.count("return"),
    }

"""**Apply feature extraction to train/val/test**"""

train_feats = train["code"].apply(extract_features).apply(pd.Series)
val_feats   = validation["code"].apply(extract_features).apply(pd.Series)
test_feats  = test["code"].apply(extract_features).apply(pd.Series)

print(train_feats.head())

"""**step 2: XGBoost Model (Strong OOD Baseline)**

This model excels on unseen languages because it uses language-agnostic statistics.
"""

from xgboost import XGBClassifier

xgb = XGBClassifier(
    n_estimators=600,
    max_depth=8,
    learning_rate=0.05,
    subsample=0.85,
    colsample_bytree=0.85,
    eval_metric="logloss"
)

xgb.fit(train_feats, train["label"])
xgb_val_pred_proba = xgb.predict_proba(val_feats)[:, 1]
xgb_val_pred = (xgb_val_pred_proba >= 0.5).astype(int)

#Evalute

print(classification_report(validation["label"], xgb_val_pred, digits=4))
print("Macro F1:", f1_score(validation["label"], xgb_val_pred, average="macro"))

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import classification_report

# Assuming validation["label"] and xgb_val_pred are already defined
report_str = classification_report(validation["label"], xgb_val_pred, output_dict=True)

# Convert report to DataFrame for easier plotting
report_df = pd.DataFrame(report_str).transpose()

# Drop 'accuracy' row if it's there and not needed for class-wise metrics
if 'accuracy' in report_df.index:
    report_df = report_df.drop('accuracy')

# Keep only precision, recall, f1-score
report_df = report_df[['precision', 'recall', 'f1-score']]

# Rename indices for better readability
report_df = report_df.rename(index={'0': 'Human', '1': 'AI', 'macro avg': 'Macro Average', 'weighted avg': 'Weighted Average'})

plt.figure(figsize=(8, 5))
sns.heatmap(report_df.iloc[:2], annot=True, cmap="YlGnBu", fmt=".4f", linewidths=.5, linecolor='black')
plt.title("XGBoost Classification Report (Validation)")
plt.ylabel("Class")
plt.xlabel("Metric")
plt.yticks(rotation=0)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 2))
sns.heatmap(report_df.iloc[2:], annot=True, cmap="YlGnBu", fmt=".4f", linewidths=.5, linecolor='black')
plt.title("XGBoost Classification Report (Averages)")
plt.ylabel("Average Type")
plt.xlabel("Metric")
plt.yticks(rotation=0)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Get feature importances from the trained XGBoost model
feature_importances = xgb.feature_importances_

# Get feature names from the training features DataFrame
feature_names = train_feats.columns

# Create a DataFrame for better visualization
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importances
})

# Sort by importance in descending order
importance_df = importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 7))
sns.barplot(x='Importance', y='Feature', hue='Feature', data=importance_df, palette='viridis', legend=False)
plt.title('XGBoost Feature Importance')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Assuming xgb_val_pred and validation["label"] are already defined and aligned
cm_xgb = confusion_matrix(validation["label"], xgb_val_pred)
class_names = ["Human (0)", "Machine (1)"]

plt.figure(figsize=(5,4))
sns.heatmap(
    cm_xgb,
    annot=True,
    fmt="d",
    xticklabels=class_names,
    yticklabels=class_names,
    cmap="Blues"
)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("XGBoost Confusion Matrix (Validation)")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd # Import pandas if not already globally available

# Ensure val_small and val_small_feats are defined for in-domain comparison
# These lines are typically from cell ZMbHGqqBRQ-T
val_small = validation.sample(10000, random_state=42).reset_index(drop=True)
val_small_feats = val_small["code"].apply(extract_features).apply(pd.Series)
xgb_id_prob = xgb.predict_proba(val_small_feats)[:, 1]

# Calculate entropy for XGBoost in-domain and OOD probabilities
def get_entropy(p):
    p = np.clip(p, 1e-12, 1 - 1e-12)   # avoid log(0)
    return - (p * np.log2(p) + (1 - p) * np.log2(1 - p))

xgb_id_entropy = get_entropy(xgb_id_prob)

# Ensure test_sample and ood_probs_xgb are defined for OOD comparison
# These lines are typically from cell 3LJbb8UA0gmJ
test_sample = pd.read_parquet("test_sample.parquet")
test_feats = test_sample["code"].apply(extract_features).apply(pd.Series)
ood_probs_xgb = xgb.predict_proba(test_feats)[:, 1]

xgb_ood_entropy = get_entropy(ood_probs_xgb)

plt.figure(figsize=(18, 5))

# Plot 1: XGBoost OOD Probability Distribution
plt.subplot(1, 3, 1)
sns.histplot(ood_probs_xgb, kde=True, bins=30, color='darkgreen')
plt.title("XGBoost OOD Probability Distribution")
plt.xlabel("P(AI | code)")
plt.ylabel("Count / Density")

# Plot 2: XGBoost OOD Entropy Distribution
plt.subplot(1, 3, 2)
sns.histplot(xgb_ood_entropy, kde=True, bins=30, color='purple')
plt.title("XGBoost OOD Entropy Distribution")
plt.xlabel("Entropy (bits)")
plt.ylabel("Count / Density")

# Plot 3: Comparative In-domain vs OOD Entropy Distribution for XGBoost
plt.subplot(1, 3, 3)
sns.kdeplot(xgb_id_entropy, fill=True, alpha=0.6, label="Validation (in-domain)", color='skyblue')
sns.kdeplot(xgb_ood_entropy, fill=True, alpha=0.6, label="OOD (test_sample)", color='salmon')
plt.title("XGBoost: In-domain vs OOD Entropy Distribution")
plt.xlabel("Entropy (bits)")
plt.ylabel("Density")
plt.legend()

plt.tight_layout()
plt.show()

print(f"Mean Entropy (XGBoost In-domain): {xgb_id_entropy.mean():.4f}")
print(f"Mean Entropy (XGBoost OOD): {xgb_ood_entropy.mean():.4f}")

"""**step 3: Transformer Encoder (GraphCodeBERT)**"""

import torch

from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_name = "microsoft/graphcodebert-base"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name, num_labels=2
)

#dataset


class CodeDataset(torch.utils.data.Dataset):
    def __init__(self, codes, labels=None):
        self.codes = codes
        self.labels = labels

    def __getitem__(self, idx):
        item = tokenizer(
            self.codes[idx],
            truncation=True,
            padding="max_length",
            max_length=256    # FAST, recommended for training
        )
        if self.labels is not None:
            item["labels"] = int(self.labels[idx])
        return item

    def __len__(self):
        return len(self.codes)

import os
os.environ["WANDB_DISABLED"] = "true"

# 1) Subsample for faster training
train_small = train.sample(50000, random_state=42).reset_index(drop=True)
val_small   = validation.sample(10000, random_state=42).reset_index(drop=True)

# 2) Build datasets from the small subsets
train_ds = CodeDataset(train_small["code"].tolist(), train_small["label"].tolist())
val_ds   = CodeDataset(val_small["code"].tolist(), val_small["label"].tolist())

from transformers import TrainingArguments, Trainer
import torch

# 3) Training arguments (fast + safe)
training_args = TrainingArguments(
    output_dir="./codebert",
    num_train_epochs=2,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    learning_rate=5e-5,
    weight_decay=0.01,
    logging_steps=200,
    save_strategy="epoch",
    fp16=True if torch.cuda.is_available() else False,
)

# 4) Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
)

# 5) Train
trainer.train()

import numpy as np
import pandas as pd
from scipy.special import softmax
from sklearn.metrics import classification_report, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1) Fix the validation subset ONCE (do NOT resample later)
val_small = validation.sample(10000, random_state=42).reset_index(drop=True)

# Ground-truth labels (aligned with val_small)
y_val = val_small["label"].values

# 2) Build dataset from this exact subset (for CodeBERT)
val_ds = CodeDataset(
    val_small["code"].tolist(),
    val_small["label"].tolist()
)

# 3) Get logits from CodeBERT for this subset
pred_output = trainer.predict(val_ds)
logits = pred_output.predictions          # shape: (N, 2)

# 4) Convert logits → probabilities with softmax
#    probs[:, 0] = P(human), probs[:, 1] = P(AI)
probs = softmax(logits, axis=1)
codebert_prob = probs[:, 1]              # P(AI | code)

# 5) Convert probabilities → predicted labels (threshold 0.5)
codebert_pred_labels = (codebert_prob >= 0.5).astype(int)

# 6) Evaluation metrics
print("=== CodeBERT Validation Report ===")
print(classification_report(y_val, codebert_pred_labels, digits=4))

print("Macro F1:", f1_score(y_val, codebert_pred_labels, average="macro"))

print("\n=== Confusion Matrix ===")
print(confusion_matrix(y_val, codebert_pred_labels))

# 7) Build dataframe for visualization (perfectly aligned)
val_df_viz = pd.DataFrame({
    "y_true": y_val,
    "codebert_prob": codebert_prob
})

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import classification_report

# Assuming y_val (from val_small) and codebert_pred_labels are already defined and aligned
report_str_cb = classification_report(y_val, codebert_pred_labels, output_dict=True)

# Convert report to DataFrame for easier plotting
report_df_cb = pd.DataFrame(report_str_cb).transpose()

# Drop 'accuracy' row if it's there and not needed for class-wise metrics
if 'accuracy' in report_df_cb.index:
    report_df_cb = report_df_cb.drop('accuracy')

# Keep only precision, recall, f1-score
report_df_cb = report_df_cb[['precision', 'recall', 'f1-score']]

# Rename indices for better readability
report_df_cb = report_df_cb.rename(index={'0': 'Human', '1': 'AI', 'macro avg': 'Macro Average', 'weighted avg': 'Weighted Average'})

plt.figure(figsize=(8, 5))
sns.heatmap(report_df_cb.iloc[:2], annot=True, cmap="YlGnBu", fmt=".4f", linewidths=.5, linecolor='black')
plt.title("CodeBERT Classification Report (Validation)")
plt.ylabel("Class")
plt.xlabel("Metric")
plt.yticks(rotation=0)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 2))
sns.heatmap(report_df_cb.iloc[2:], annot=True, cmap="YlGnBu", fmt=".4f", linewidths=.5, linecolor='black')
plt.title("CodeBERT Classification Report (Averages)")
plt.ylabel("Average Type")
plt.xlabel("Metric")
plt.yticks(rotation=0)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 8) KDE plot of predicted probabilities by true class

import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.patches as mpatches

plt.figure(figsize=(8, 5))

# KDE plot
ax = sns.kdeplot(
    data=val_df_viz,
    x="codebert_prob",
    hue="y_true",
    palette={0: "darkorange", 1: "steelblue"}, # Changed colors
    hue_order=[0, 1],
    fill=True,
    common_norm=False,
    bw_adjust=1.0
)

plt.title("CodeBERT Predicted Probabilities by True Class", fontsize=14)
plt.xlabel("P(AI | code)", fontsize=12)
plt.ylabel("Density", fontsize=12)

# Add classification threshold line
plt.axvline(x=0.5, color='gray', linestyle='--', label='Classification Threshold')

# Add a grid
plt.grid(axis='y', linestyle='--', alpha=0.7)

# ---- REMOVE SEABORN AUTOMATIC LEGEND ----
ax.legend_.remove()

# ---- MANUAL FIXED LEGEND ----
human_patch = mpatches.Patch(color="darkorange", label="Human (0)")
ai_patch = mpatches.Patch(color="steelblue", label="AI (1)")
threshold_patch = mpatches.Patch(color='gray', linestyle='--', label='Classification Threshold', fill=False)

plt.legend(
    handles=[human_patch, ai_patch, threshold_patch],
    title="True label",
    loc="upper center",
    frameon=True
)

plt.tight_layout()
plt.show()

#9 ROC curve (separation quality)

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

fpr, tpr, _ = roc_curve(y_val, codebert_prob)
auc = roc_auc_score(y_val, codebert_prob)

plt.figure(figsize=(5,5))
plt.plot(fpr, tpr, label=f"AUC = {auc:.4f}")
plt.plot([0,1], [0,1], "k--", alpha=0.6)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve – CodeBERT")
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

#10 Precision–Recall curve (good when classes can be imbalanced)

from sklearn.metrics import precision_recall_curve, average_precision_score

prec, rec, _ = precision_recall_curve(y_val, codebert_prob)
ap = average_precision_score(y_val, codebert_prob)

plt.figure(figsize=(5,5))
plt.plot(rec, prec, label=f"AP = {ap:.4f}")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision–Recall Curve – CodeBERT")
plt.grid(alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

#11 Confusion matrix heatmap

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_val, codebert_pred_labels)

plt.figure(figsize=(4,4))
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=["Human (0)", "AI (1)"],
    yticklabels=["Human (0)", "AI (1)"]
)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("Confusion Matrix – CodeBERT")
plt.tight_layout()
plt.show()

"""**Run CodeBERT on test_sample.parquet**

(the mini OOD evaluation set released by SemEval)
"""

test_sample = pd.read_parquet("test_sample.parquet")
test_sample.head()

# Build dataset for CodeBERT
test_sample_ds = CodeDataset(
    test_sample["code"].tolist(),
    None  # no labels provided
)

# Get logits from CodeBERT
output = trainer.predict(test_sample_ds)
logits = output.predictions
probs = softmax(logits, axis=1)[:, 1]  # P(AI)

test_sample["prob"] = probs
test_sample["pred"] = (probs >= 0.5).astype(int)

"""Since test_sample has no labels, you evaluate robustness by analyzing:

Distribution of probabilities

Calibration

Entropy

Compare with validation distributions

Look for shifts between Human vs AI confidence curves
"""

#1 Visualize Probability Distribution on OOD

plt.figure(figsize=(8,5))
sns.histplot(test_sample["prob"], kde=True, bins=30, color='teal') # Changed color
plt.title("CodeBERT Predicted Probability Distribution on OOD Sample (test_sample.parquet)")
plt.xlabel("P(AI | code)")
plt.ylabel("Count / Density")
plt.axvline(x=0.5, color='red', linestyle='--', label='Classification Threshold') # Add threshold line
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7) # Add a grid
plt.tight_layout()
plt.show()

#2 Compare In-Domain (validation) vs OOD distribution

plt.figure(figsize=(8,5))
sns.kdeplot(val_df_viz["codebert_prob"], fill=True, alpha=0.6, label="In-Domain (Validation)", color='skyblue')
sns.kdeplot(test_sample["prob"], fill=True, alpha=0.6, label="OOD Sample", color="red")
plt.legend()
plt.title("CodeBERT Predicted Probability Distribution: In-Domain vs OOD")
plt.xlabel("P(AI | code)")
plt.ylabel("Density") # Added Y-axis label
plt.grid(axis='y', linestyle='--', alpha=0.7) # Added grid
plt.tight_layout()
plt.show()

#3 Measure OOD Uncertainty (Entropy)

test_sample["entropy"] = -1 * (
    probs * np.log2(probs) +
    (1 - probs) * np.log2(1 - probs)
)

plt.figure(figsize=(8,5)) # Setting figure size for better display
sns.kdeplot(test_sample["entropy"], fill=True, color='purple') # Added fill and specific color
plt.title("CodeBERT Prediction Entropy on OOD Sample") # Clearer title
plt.xlabel("Entropy (bits)") # Labeled x-axis
plt.ylabel("Density") # Labeled y-axis
plt.grid(axis='y', linestyle='--', alpha=0.7) # Added a grid
plt.tight_layout()
plt.show()

"""**step 4: ENSEMBLE (Best for OOD)**

Late fusion improves unseen languages dramatically.

Build a Simple Ensemble: XGBoost + CodeBERT

Right now:

CodeBERT = strong in-domain, but overconfident OOD

XGBoost = weaker in-domain, but more stable OOD

So let’s compute a weighted average of their probabilities:

and choose the best w and threshold using the validation set.
"""

#Step 1: Get XGBoost probs on the same validation subset

# 0) Fix the validation subset ONCE
val_small = validation.sample(10000, random_state=42).reset_index(drop=True)
y_val = val_small["label"].values

# 1) CodeBERT probs on this exact val_small
val_ds = CodeDataset(
    val_small["code"].tolist(),
    val_small["label"].tolist()
)
pred_output = trainer.predict(val_ds)
logits = pred_output.predictions
codebert_prob = softmax(logits, axis=1)[:, 1]   # shape (10000,)

# 2) XGBoost probs on this exact SAME val_small
val_small_feats = val_small["code"].apply(extract_features).apply(pd.Series)
xgb_val_prob = xgb.predict_proba(val_small_feats)[:, 1]  # shape (10000,)

#Step 2: Grid-search ensemble weight and threshold

from sklearn.metrics import f1_score

best_f1 = 0.0
best_w = None
best_th = None

for w in np.linspace(0, 1, 21):
    ens_prob = w * codebert_prob + (1 - w) * xgb_val_prob

    for th in np.linspace(0.2, 0.8, 25):
        ens_pred = (ens_prob >= th).astype(int)
        f1 = f1_score(y_val, ens_pred, average="macro")

        if f1 > best_f1:
            best_f1 = f1
            best_w = w
            best_th = th

print("Best ensemble weight w:", best_w)
print("Best threshold:", best_th)
print("Best macro F1 on validation:", best_f1)

#Evaluate

from sklearn.metrics import classification_report, f1_score, confusion_matrix

# We already computed ±:
# codebert_prob
# xgb_val_prob
# best_w, best_th
# y_val

ens_val_prob = best_w * codebert_prob + (1 - best_w) * xgb_val_prob
ens_val_pred = (ens_val_prob >= best_th).astype(int)

print("=== ENSEMBLE VALIDATION RESULTS ===")
print(classification_report(y_val, ens_val_pred, digits=4))

print("Macro F1 (Ensemble):", f1_score(y_val, ens_val_pred, average="macro"))
print("\nConfusion Matrix:\n", confusion_matrix(y_val, ens_val_pred))

#Step 3: Use the ensemble on OOD (test_sample.parquet)

# On OOD
test_sample = pd.read_parquet("test_sample.parquet")

# CodeBERT probs on OOD
test_ds = CodeDataset(test_sample["code"].tolist(), None)
pred_output = trainer.predict(test_ds)
ood_probs_codebert = softmax(pred_output.predictions, axis=1)[:, 1]

# XGBoost probs on OOD
test_feats = test_sample["code"].apply(extract_features).apply(pd.Series)
ood_probs_xgb = xgb.predict_proba(test_feats)[:, 1]

# Ensemble
ood_ens_prob = best_w * ood_probs_codebert + (1 - best_w) * ood_probs_xgb
ood_ens_pred = (ood_ens_prob >= best_th).astype(int)

plt.figure(figsize=(8,5))
sns.kdeplot(ood_probs_codebert, label="CodeBERT (OOD)", linestyle="--")
sns.kdeplot(ood_probs_xgb, label="XGB (OOD)", linestyle="-.")
sns.kdeplot(ood_ens_prob, label="Ensemble (OOD)", linestyle="-")
plt.title("OOD Probability Distribution: CodeBERT vs XGBoost vs Ensemble")
plt.xlabel("P(AI | code)")
plt.ylabel("Density")
plt.legend()
plt.show()

"""**NEXT STEP  — Compute quantitative shift metrics**"""

#1. KL divergence between ID and OOD

from scipy.stats import entropy

# ID
hist_id, bins = np.histogram(codebert_prob, bins=50, range=(0,1), density=True)

# OOD
hist_ood, _ = np.histogram(ood_probs_codebert, bins=bins, density=True)

kl_codebert = entropy(hist_ood, hist_id)
print("CodeBERT KL Divergence:", kl_codebert)

# Ensemble
hist_ood_ens, _ = np.histogram(ood_ens_prob, bins=bins, density=True)
kl_ensemble = entropy(hist_ood_ens, hist_id)
print("Ensemble KL Divergence:", kl_ensemble)

#FIX KL Divergence

#Use Jensen-Shannon divergence

from scipy.spatial.distance import jensenshannon

jsd_codebert = jensenshannon(hist_ood_smooth, hist_id_smooth)**2
jsd_ensemble = jensenshannon(hist_ood_ens_smooth, hist_id_smooth)**2

print("JSD CodeBERT:", jsd_codebert)
print("JSD Ensemble:", jsd_ensemble)

#Compute OOD entropy mean:

import numpy as np

def get_entropy(p):
    p = np.clip(p, 1e-12, 1 - 1e-12)   # avoid log(0)
    return - (p * np.log2(p) + (1 - p) * np.log2(1 - p))

# 1. Entropy for CodeBERT on OOD
entropy_ood = get_entropy(ood_probs_codebert)

# 2. Entropy for Ensemble on OOD
entropy_ens = get_entropy(ood_ens_prob)

print("Mean Entropy(CodeBERT OOD):", entropy_ood.mean())
print("Mean Entropy(Ensemble OOD):", entropy_ens.mean())

"""Mean Entropy(CodeBERT OOD) ≈ 0.06 →
The model is extremely overconfident on unseen domains/languages. It’s basically saying “I’m 100% sure” almost all the time, even when the code is OOD. That’s exactly what we saw in the spiky KDE plots.

Mean Entropy(Ensemble OOD) ≈ 0.34 →
The ensemble is much more uncertain on OOD inputs. This is good: a robust detector should show higher uncertainty on unfamiliar distributions instead of confidently hallucinating

**Finalize the Ensemble**
"""

def predict_ensemble(codes, w=0.5, th=0.5):
    # CodeBERT
    ds = CodeDataset(codes, None)
    out = trainer.predict(ds)
    p_cb = softmax(out.predictions, axis=1)[:, 1]

    # XGBoost
    feats = pd.Series(codes).apply(extract_features).apply(pd.Series)
    p_xgb = xgb.predict_proba(feats)[:, 1]

    # Ensemble
    p = w * p_cb + (1 - w) * p_xgb
    y = (p >= th).astype(int)
    return p, y

p_test, y_test = predict_ensemble(test["code"].tolist())

#Create the Competition Submission File

# Attach predictions
test["label"] = y_test.astype(int)

# Save exactly in required format
test[["ID", "label"]].to_csv("submission.csv", index=False)

print("Saved: submission.csv")

"""## Analyze Current Ensemble Strategy


Briefly review the existing fixed-weight ensemble strategy and its limitations, especially concerning out-of-domain (OOD) data and the differing confidence behaviors of CodeBERT and XGBoost.

The existing ensemble strategy combines the probabilities from CodeBERT and XGBoost using a simple fixed-weight average:

`ens_prob = w * codebert_prob + (1 - w) * xgb_val_prob`

This `w` (weight) and a classification `threshold` (`th`) are optimized through a grid search on a small validation subset (`val_small.parquet`) to maximize the macro F1 score. The notebook found `best_w = 0.5` and `best_th = 0.5`, indicating an equal weighting between CodeBERT and XGBoost predictions, and a standard classification threshold.

### Validation Results

**Individual Models vs. Ensemble (Validation Set):**

*   **TF-IDF + Logistic Regression (Baseline):** Macro F1: ~0.9557
*   **XGBoost (Feature-engineered):** Macro F1: ~0.9598
*   **CodeBERT (Fine-tuned):** Macro F1: ~0.9882
*   **Fixed-Weight Ensemble (on `val_small`):** Macro F1: ~0.9893

The ensemble shows a slight improvement over CodeBERT alone on the in-domain validation set, suggesting that combining the models (even with fixed weights) adds value, likely by leveraging XGBoost's structural understanding alongside CodeBERT's semantic capabilities.

### OOD Performance & Confidence

When evaluated on the `test_sample.parquet` (OOD set):

*   **CodeBERT OOD Probability Distribution:** Exhibits high confidence, with probabilities heavily skewed towards 0 or 1, resulting in a very low mean entropy (~0.06).
*   **XGBoost OOD Probability Distribution:** Shows a more spread-out distribution, with probabilities often closer to 0.5, leading to higher mean entropy (~0.34).
*   **Ensemble OOD Probability Distribution:** The ensemble's probability distribution on OOD data tends to be more balanced than CodeBERT's alone. The mean entropy for the ensemble on OOD data (~0.34) is significantly higher than CodeBERT's, indicating that the ensemble effectively mitigates CodeBERT's overconfidence by incorporating XGBoost's more uncertain (and likely more reliable for OOD) predictions.

**Key Observation:** CodeBERT is extremely overconfident on OOD data, while XGBoost shows more appropriate uncertainty. The ensemble, by averaging, leverages XGBoost's robustness to provide a more calibrated confidence score for OOD inputs, even with a fixed weighting.

## Define Dynamic Weighting Mechanism

Propose a method for dynamically adjusting the weights of CodeBERT and XGBoost based on their predicted confidence (entropy) for each individual sample, with a focus on mitigating CodeBERT's overconfidence on OOD data.

**Reasoning**:
The subtask requires defining a function to calculate entropy and another function to dynamically adjust CodeBERT's weight based on its confidence. I will create a code block to define these two functions as specified in the instructions.
"""

import numpy as np

def get_entropy(p_value):
    """Calculates the binary entropy for a given probability p_value."""
    p_value = np.clip(p_value, 1e-12, 1 - 1e-12) # Clip to avoid log(0) errors
    return - (p_value * np.log2(p_value) + (1 - p_value) * np.log2(1 - p_value))

def calculate_dynamic_codebert_weight(codebert_prob, base_w=0.5, min_w=0.3, overconf_threshold_entropy=0.1):
    """Dynamically adjusts CodeBERT's weight based on its predicted confidence (entropy)."""
    entropy_cb = get_entropy(codebert_prob)

    # Initialize dynamic weight
    w_dynamic = np.full_like(codebert_prob, base_w, dtype=float)

    # Logic to adjust CodeBERT's weight if entropy is low (indicating high confidence)
    # If entropy_cb < overconf_threshold_entropy, reduce CodeBERT's weight linearly
    # from base_w (at overconf_threshold_entropy) to min_w (at 0 entropy).
    # Otherwise, keep it at base_w.
    mask_low_entropy = entropy_cb < overconf_threshold_entropy
    if np.any(mask_low_entropy):
        # Linear interpolation for samples with low entropy
        # entropy_cb_masked ranges from 0 to overconf_threshold_entropy
        entropy_cb_masked = entropy_cb[mask_low_entropy]

        # Interpolate between min_w and base_w.
        # When entropy is 0, w_dynamic is min_w.
        # When entropy is overconf_threshold_entropy, w_dynamic is base_w.
        interpolation_factor = entropy_cb_masked / overconf_threshold_entropy
        w_dynamic[mask_low_entropy] = min_w + (base_w - min_w) * interpolation_factor

    # Ensure the dynamic weight is clipped between 0 and 1
    w_dynamic = np.clip(w_dynamic, 0.0, 1.0)

    return w_dynamic

print("Defined get_entropy and calculate_dynamic_codebert_weight functions.")

"""This dynamic weighting mechanism aims to address CodeBERT's observed overconfidence on out-of-domain samples. The `calculate_dynamic_codebert_weight` function works as follows:

1.  **Calculate CodeBERT's Entropy**: For each prediction, the binary entropy of CodeBERT's probability (`codebert_prob`) is calculated using `get_entropy`.
2.  **Identify High Confidence**: If CodeBERT's entropy for a specific sample falls below a predefined `overconf_threshold_entropy` (e.g., 0.1 bits), it indicates that CodeBERT is making a very confident prediction (close to 0 or 1).
3.  **Adjust Weight for High Confidence**: For these high-confidence predictions, CodeBERT's weight (`w_dynamic`) is reduced. The reduction is linear: if the entropy is 0 (absolute certainty), its weight drops to `min_w` (e.g., 0.3). If the entropy is at `overconf_threshold_entropy`, its weight remains at `base_w` (e.g., 0.5). For all other samples where entropy is above the threshold, CodeBERT retains its `base_w` weight.
4.  **Implicit XGBoost Weight**: The weight for XGBoost implicitly becomes `1 - w_dynamic` for each sample.

**Benefit**: By reducing CodeBERT's influence when it is overly confident (especially on samples with very low entropy that might be OOD), this mechanism mitigates its tendency to make strong, potentially incorrect, assertions on unfamiliar data. This allows the more robust, albeit less precise, XGBoost model to contribute more significantly in scenarios where CodeBERT might otherwise be overconfident and wrong, leading to better overall OOD generalization and more calibrated predictions from the ensemble.

This dynamic weighting mechanism aims to address CodeBERT's observed overconfidence on out-of-domain samples. The `calculate_dynamic_codebert_weight` function works as follows:

1.  **Calculate CodeBERT's Entropy**: For each prediction, the binary entropy of CodeBERT's probability (`codebert_prob`) is calculated using `get_entropy`.
2.  **Identify High Confidence**: If CodeBERT's entropy for a specific sample falls below a predefined `overconf_threshold_entropy` (e.g., 0.1 bits), it indicates that CodeBERT is making a very confident prediction (close to 0 or 1).
3.  **Adjust Weight for High Confidence**: For these high-confidence predictions, CodeBERT's weight (`w_dynamic`) is reduced. The reduction is linear: if the entropy is 0 (absolute certainty), its weight drops to `min_w` (e.g., 0.3). If the entropy is at `overconf_threshold_entropy`, its weight remains at `base_w` (e.g., 0.5). For all other samples where entropy is above the threshold, CodeBERT retains its `base_w` weight.
4.  **Implicit XGBoost Weight**: The weight for XGBoost implicitly becomes `1 - w_dynamic` for each sample.

**Benefit**: By reducing CodeBERT's influence when it is overly confident (especially on samples with very low entropy that might be OOD), this mechanism mitigates its tendency to make strong, potentially incorrect, assertions on unfamiliar data. This allows the more robust, albeit less precise, XGBoost model to contribute more significantly in scenarios where CodeBERT might otherwise be overconfident and wrong, leading to better overall OOD generalization and more calibrated predictions from the ensemble.

**Reasoning**:
Implement a new ensemble prediction function `predict_ensemble_dynamic` that incorporates the previously defined dynamic weighting mechanism for CodeBERT based on its entropy.
"""

import pandas as pd
from scipy.special import softmax

def predict_ensemble_dynamic(codes, base_w=0.5, min_w=0.3, overconf_threshold_entropy=0.1, ensemble_threshold=0.5):
    # CodeBERT probabilities
    ds = CodeDataset(codes, None)
    out = trainer.predict(ds)
    p_cb = softmax(out.predictions, axis=1)[:, 1]

    # XGBoost probabilities
    feats = pd.Series(codes).apply(extract_features).apply(pd.Series)
    p_xgb = xgb.predict_proba(feats)[:, 1]

    # Calculate dynamic CodeBERT weights
    w_dynamic = calculate_dynamic_codebert_weight(
        p_cb,
        base_w=base_w,
        min_w=min_w,
        overconf_threshold_entropy=overconf_threshold_entropy
    )

    # Ensemble probabilities using dynamic weights
    p_ensemble = w_dynamic * p_cb + (1 - w_dynamic) * p_xgb
    y_pred = (p_ensemble >= ensemble_threshold).astype(int)

    print(f"Mean dynamic CodeBERT weight (w_dynamic): {w_dynamic.mean():.4f}")

    return p_ensemble, y_pred, w_dynamic

print("Defined predict_ensemble_dynamic function.")

"""**Reasoning**:
Now that the `predict_ensemble_dynamic` function is defined, I will apply it to the validation subset (`val_small`) to evaluate its performance and compare it with the previously established fixed-weight ensemble and individual models.


"""

print("Evaluating dynamic ensemble on validation set...")

# Ensure val_small and y_val are consistent as previously defined
# (They were created in cell ZMbHGqqBRQ-T and used again in FnBlG6Ft0FQI)
# val_small = validation.sample(10000, random_state=42).reset_index(drop=True)
# y_val = val_small["label"].values

# Get dynamic ensemble predictions for the validation set
ens_val_prob_dynamic, ens_val_pred_dynamic, w_dynamic_val = predict_ensemble_dynamic(
    val_small["code"].tolist(),
    base_w=0.5,
    min_w=0.3,
    overconf_threshold_entropy=0.1,
    ensemble_threshold=0.5 # Use the best_th found in fixed ensemble
)

print("\n=== DYNAMIC ENSEMBLE VALIDATION RESULTS ===")
print(classification_report(y_val, ens_val_pred_dynamic, digits=4))

print("Macro F1 (Dynamic Ensemble):", f1_score(y_val, ens_val_pred_dynamic, average="macro"))
print("\nConfusion Matrix:\n", confusion_matrix(y_val, ens_val_pred_dynamic))

#plot Confusion Matrix:

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# ens_val_pred_dynamic and y_val should be available from previous executions
cm_dynamic_ensemble = confusion_matrix(y_val, ens_val_pred_dynamic)
class_names = ["Human (0)", "Machine (1)"]

plt.figure(figsize=(5,4))
sns.heatmap(
    cm_dynamic_ensemble,
    annot=True,
    fmt="d",
    xticklabels=class_names,
    yticklabels=class_names,
    cmap="Blues"
)
plt.xlabel("Predicted label")
plt.ylabel("True label")
plt.title("Dynamic Ensemble Confusion Matrix (Validation)")
plt.tight_layout()
plt.show()

"""### Analysis of Dynamic Ensemble Performance on Validation Set

The dynamic weighting mechanism was applied to the ensemble model, and its performance was evaluated on the `val_small` (validation) dataset.

**Key Results:**

*   **Mean dynamic CodeBERT weight (w_dynamic):** 0.3141
    *   This indicates that, on average, CodeBERT's weight was reduced from the `base_w=0.5` to an average of `0.3141` across the validation samples. This confirms that the dynamic weighting logic is actively reducing CodeBERT's influence, particularly when it is highly confident (low entropy).

*   **Macro F1 (Dynamic Ensemble):** 0.9753
    *   This is lower than the 0.9893 Macro F1 achieved by the fixed-weight ensemble on the same `val_small` dataset.

*   **Comparison to Individual Models (Validation):**
    *   XGBoost (Feature-engineered): Macro F1: ~0.9598
    *   CodeBERT (Fine-tuned): Macro F1: ~0.9882
    *   Fixed-Weight Ensemble: Macro F1: ~0.9893
    *   **Dynamic Ensemble: Macro F1: ~0.9753**

**Interpretation:**

On the *in-domain* validation set, the dynamic ensemble strategy resulted in a **decrease** in Macro F1 score compared to both the fixed-weight ensemble and CodeBERT alone. This suggests that for in-domain data, CodeBERT's high confidence is generally accurate, and reducing its weight (even when it is very confident) introduces more errors than it corrects.

**Why the drop?**

The primary goal of dynamic weighting is to improve *Out-of-Distribution (OOD)* generalization and calibration by mitigating CodeBERT's overconfidence in scenarios where it might be confidently wrong. However, on in-domain data, CodeBERT's high confidence likely correlates with high accuracy. By reducing its weight in these cases, the ensemble gives more influence to XGBoost, which, while robust to OOD, is less accurate on in-domain data than CodeBERT. This trade-off leads to a dip in performance on the validation set.

**Next Steps:**

While the performance on the validation set has decreased, the true test for this dynamic weighting mechanism lies in its ability to improve performance and calibration on *out-of-domain* data. It's crucial to evaluate this dynamic ensemble on the `test_sample.parquet` and compare its OOD entropy and probability distributions against the fixed-weight ensemble to see if the intended benefit (better OOD robustness) is achieved.

**Reasoning**:
Apply the newly defined `predict_ensemble_dynamic` function to the `test_sample.parquet` dataset to obtain dynamic ensemble predictions for Out-of-Domain data.
"""

print("Applying dynamic ensemble on OOD test_sample...")

# On OOD
test_sample_ood = pd.read_parquet("test_sample.parquet")

# Get dynamic ensemble predictions for the OOD test_sample set
ood_ens_prob_dynamic, ood_ens_pred_dynamic, w_dynamic_ood = predict_ensemble_dynamic(
    test_sample_ood["code"].tolist(),
    base_w=0.5,
    min_w=0.3,
    overconf_threshold_entropy=0.1,
    ensemble_threshold=0.5 # Use the best_th found in fixed ensemble
)

# Calculate entropy for the dynamic ensemble on OOD
entropy_ood_ens_dynamic = get_entropy(ood_ens_prob_dynamic)

print("Dynamic ensemble applied to OOD test_sample.")

"""**Reasoning**:
Visualize the predicted probability distribution of the dynamic ensemble on the OOD `test_sample` dataset to understand its behavior and compare it with the previous fixed-weight ensemble's distribution.


"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.histplot(ood_ens_prob_dynamic, kde=True, bins=30, color='darkcyan')
plt.title("Dynamic Ensemble Predicted Probability Distribution on OOD Sample")
plt.xlabel("P(AI | code)")
plt.ylabel("Count / Density")
plt.axvline(x=0.5, color='red', linestyle='--', label='Classification Threshold')
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""**Reasoning**:
To compare the dynamic ensemble's probability distribution with the fixed-weight ensemble and individual models on OOD data, I will create a KDE plot that visualizes all these distributions together. This will allow for a direct visual comparison of their confidence profiles.


"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from scipy.special import softmax

# Re-compute CodeBERT and XGBoost OOD probabilities
# This logic is extracted from cell 3LJbb8UA0gmJ to ensure variables are defined
test_sample_current = pd.read_parquet("test_sample.parquet")

# CodeBERT probs on OOD
test_ds_for_plot = CodeDataset(test_sample_current["code"].tolist(), None)
pred_output_for_plot = trainer.predict(test_ds_for_plot)
ood_probs_codebert = softmax(pred_output_for_plot.predictions, axis=1)[:, 1]

# XGBoost probs on OOD
test_feats_for_plot = test_sample_current["code"].apply(extract_features).apply(pd.Series)
ood_probs_xgb = xgb.predict_proba(test_feats_for_plot)[:, 1]

# Fixed Ensemble OOD probabilities (using best_w and best_th from validation, previously 0.5 and 0.5)
# Assuming best_w and best_th are still in scope from previous execution
ood_ens_prob = best_w * ood_probs_codebert + (1 - best_w) * ood_probs_xgb

plt.figure(figsize=(10,6))
sns.kdeplot(ood_probs_codebert, label="CodeBERT (OOD)", linestyle="--", color='skyblue', fill=True, alpha=0.5)
sns.kdeplot(ood_probs_xgb, label="XGBoost (OOD)", linestyle="-.", color='green', fill=True, alpha=0.5)
sns.kdeplot(ood_ens_prob, label="Fixed Ensemble (OOD)", linestyle="-", color='orange', fill=True, alpha=0.5)
sns.kdeplot(ood_ens_prob_dynamic, label="Dynamic Ensemble (OOD)", linestyle="-", color='purple', fill=True, alpha=0.5)

plt.title("OOD Probability Distribution: Models vs. Ensembles")
plt.xlabel("P(AI | code)")
plt.ylabel("Density")
plt.axvline(x=0.5, color='red', linestyle='--', label='Classification Threshold')
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## Evaluate Dynamic Ensemble on OOD Set

Quantitatively evaluate the dynamic ensemble's performance on the Out-of-Domain (OOD) `test_sample.parquet` by comparing its entropy and Jensen-Shannon Divergence with the fixed-weight ensemble and individual models.

**Reasoning**:
To quantitatively evaluate the dynamic ensemble, I will first calculate and print the mean entropy for CodeBERT, the fixed ensemble, and the dynamic ensemble on the OOD data. Then, I will compute the Jensen-Shannon Divergence for the dynamic ensemble's OOD probability distribution relative to the in-domain validation distribution, comparing it with CodeBERT and the fixed ensemble.
"""

print("\n=== OOD Entropy Comparison ===")
# 1. Entropy for CodeBERT on OOD
entropy_ood_codebert = get_entropy(ood_probs_codebert)

# 2. Entropy for Fixed Ensemble on OOD
entropy_ood_fixed_ensemble = get_entropy(ood_ens_prob)

# 3. Entropy for Dynamic Ensemble on OOD (already computed as entropy_ood_ens_dynamic)

print(f"Mean Entropy (CodeBERT OOD): {entropy_ood_codebert.mean():.4f}")
print(f"Mean Entropy (Fixed Ensemble OOD): {entropy_ood_fixed_ensemble.mean():.4f}")
print(f"Mean Entropy (Dynamic Ensemble OOD): {entropy_ood_ens_dynamic.mean():.4f}")


print("\n=== Jensen-Shannon Divergence Comparison ===")
from scipy.stats import entropy
from scipy.spatial.distance import jensenshannon

# Define the number of bins and range for histograms
bins = 50
hist_range = (0, 1)

# 1. In-domain validation histogram (from CodeBERT validation probs)
# Make sure codebert_prob (val_small, in-domain) is available. It is in the kernel state.
hist_id, _ = np.histogram(codebert_prob, bins=bins, range=hist_range, density=True)

# 2. OOD CodeBERT histogram
hist_ood_codebert, _ = np.histogram(ood_probs_codebert, bins=bins, range=hist_range, density=True)

# 3. OOD Fixed Ensemble histogram
hist_ood_fixed_ensemble, _ = np.histogram(ood_ens_prob, bins=bins, range=hist_range, density=True)

# 4. OOD Dynamic Ensemble histogram
hist_ood_ens_dynamic, _ = np.histogram(ood_ens_prob_dynamic, bins=bins, range=hist_range, density=True)

# To avoid issues with zero probabilities in JSD, add a small epsilon or smooth if necessary.
# A common approach for JSD is to use np.clip to ensure no zeros.
epsilon = 1e-12
hist_id_smooth = np.clip(hist_id, epsilon, None)
hist_ood_codebert_smooth = np.clip(hist_ood_codebert, epsilon, None)
hist_ood_fixed_ensemble_smooth = np.clip(hist_ood_fixed_ensemble, epsilon, None)
hist_ood_ens_dynamic_smooth = np.clip(hist_ood_ens_dynamic, epsilon, None)

jsd_codebert = jensenshannon(hist_ood_codebert_smooth, hist_id_smooth)**2
jsd_fixed_ensemble = jensenshannon(hist_ood_fixed_ensemble_smooth, hist_id_smooth)**2
jsd_dynamic_ensemble = jensenshannon(hist_ood_ens_dynamic_smooth, hist_id_smooth)**2

print(f"JSD CodeBERT (OOD vs ID): {jsd_codebert:.4f}")
print(f"JSD Fixed Ensemble (OOD vs ID): {jsd_fixed_ensemble:.4f}")
print(f"JSD Dynamic Ensemble (OOD vs ID): {jsd_dynamic_ensemble:.4f}")

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Data for the plot
model_names = ["CodeBERT OOD", "XGBoost OOD", "Fixed Ensemble OOD", "Dynamic Ensemble OOD"]
mean_entropies = [0.0846, 0.3359, 0.3460, 0.3746]

# Create a DataFrame for easy plotting
entropy_df = pd.DataFrame({
    'Model': model_names,
    'Mean Entropy': mean_entropies
})

plt.figure(figsize=(10, 6))
barplot = sns.barplot(x='Model', y='Mean Entropy', hue='Model', data=entropy_df, palette='viridis', legend=False)
plt.xlabel("Model")
plt.ylabel("Mean Entropy (bits)")
plt.title("Mean Entropy Comparison on OOD Data")
plt.ylim(0, 0.45) # Adjust y-limit for better visualization of differences

# Add value annotations on top of each bar
for index, value in enumerate(mean_entropies):
    barplot.text(index, value + 0.01, f'{value:.4f}', color='black', ha="center", va="bottom")

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## Summary:

### Q&A

**1. Summarize the proposed dynamic confidence weighting strategy:**
The proposed dynamic confidence weighting strategy adjusts the contribution of CodeBERT and XGBoost based on CodeBERT's predicted uncertainty (entropy) for each individual sample. Specifically, if CodeBERT's entropy for a sample falls below a predefined threshold (e.g., 0.1 bits), indicating high confidence, its weight in the ensemble is linearly reduced from a base weight (e.g., 0.5) down to a minimum weight (e.g., 0.3) as its confidence increases (entropy approaches zero). For samples where CodeBERT's entropy is above the threshold, it retains its base weight. The XGBoost model's weight implicitly becomes `1 - w_dynamic`.

**2. Describe its implementation:**
The implementation involves:
*   A `get_entropy` function to calculate binary entropy for a given probability.
*   A `calculate_dynamic_codebert_weight` function that takes CodeBERT's probabilities, a base weight, a minimum weight, and an overconfidence entropy threshold. It computes CodeBERT's entropy and adjusts its weight according to the described linear reduction logic for low-entropy samples.
*   A `predict_ensemble_dynamic` function that orchestrates the process: it obtains probabilities from CodeBERT and XGBoost, calculates the dynamic weights for CodeBERT using `calculate_dynamic_codebert_weight`, and then combines the model probabilities using these sample-specific dynamic weights.

**3. Explain the expected benefits for generalization and OOD performance:**
The primary expected benefit is to improve Out-of-Domain (OOD) generalization and calibration by mitigating CodeBERT's tendency for overconfidence on unfamiliar data. By reducing CodeBERT's influence when it is overly confident (indicated by very low entropy), the mechanism allows the more robust XGBoost model to contribute more significantly. This leads to more calibrated predictions for OOD inputs, better expression of uncertainty, and enhanced ability to detect distributional shifts between in-domain and OOD data, ultimately improving the ensemble's robustness in OOD scenarios.

### Data Analysis Key Findings

*   **Fixed-Weight Ensemble Performance (In-Domain)**: The fixed-weight ensemble (w=0.5) achieved a Macro F1 of approximately 0.9893 on the in-domain validation set, slightly outperforming CodeBERT alone (Macro F1: ~0.9882) and XGBoost (Macro F1: ~0.9598).
*   **CodeBERT Overconfidence on OOD**: CodeBERT exhibited significant overconfidence on OOD data, with a very low mean entropy (~0.06). Its probability distribution on OOD data was very similar to its in-domain distribution (JSD of ~0.1091).
*   **Fixed Ensemble Partially Mitigates Overconfidence on OOD**: The fixed ensemble significantly increased the mean entropy on OOD data to ~0.34, indicating better calibration than CodeBERT alone. It also showed a higher Jensen-Shannon Divergence (JSD) of ~0.2766 when comparing OOD vs. in-domain probability distributions, suggesting it's better at recognizing distributional shifts than CodeBERT.
*   **Dynamic Ensemble Performance (In-Domain)**: On the in-domain validation set, the dynamic ensemble resulted in a lower Macro F1 score of **0.9753** compared to the fixed-weight ensemble (0.9893). The mean dynamic CodeBERT weight was **0.3141**, indicating active weight reduction.
*   **Dynamic Ensemble Improves OOD Calibration and Shift Detection**:
    *   **Mean Entropy (OOD)**: The dynamic ensemble achieved the highest mean entropy on OOD data at **0.3746**, further improving upon the fixed ensemble (0.3460). This indicates more calibrated and less overconfident predictions.
    *   **Jensen-Shannon Divergence (OOD vs. In-Domain)**: The dynamic ensemble had the highest JSD of **0.2940**, surpassing the fixed ensemble (0.2766). This signifies an improved ability to detect and react to distributional shifts in OOD data.
*   **Trade-off Observed**: While the dynamic ensemble showed a decrease in in-domain performance (Macro F1), it demonstrably improved uncertainty calibration and OOD detection capabilities as measured by mean entropy and JSD on OOD data.

### Insights or Next Steps

*   The dynamic confidence weighting mechanism successfully addresses CodeBERT's overconfidence in OOD scenarios, leading to more calibrated predictions and better OOD distributional shift detection, which is crucial for robust performance in real-world, uncertain environments.
*   Future work could involve optimizing the dynamic weighting parameters (`base_w`, `min_w`, `overconf_threshold_entropy`) on a representative OOD dataset or a synthetic OOD proxy to fine-tune the trade-off between in-domain performance and OOD robustness.

"""

import pandas as pd
from scipy.special import softmax

def predict_ensemble_dynamic_final(codes):
    # CodeBERT probabilities
    ds = CodeDataset(codes, None)
    out = trainer.predict(ds)
    p_cb = softmax(out.predictions, axis=1)[:, 1]

    # XGBoost probabilities
    feats = pd.Series(codes).apply(extract_features).apply(pd.Series)
    p_xgb = xgb.predict_proba(feats)[:, 1]

    # Calculate dynamic CodeBERT weights
    w_dynamic = calculate_dynamic_codebert_weight(
        p_cb,
        base_w=0.5,
        min_w=0.3,
        overconf_threshold_entropy=0.1
    )

    # Ensemble probabilities using dynamic weights
    p_ensemble = w_dynamic * p_cb + (1 - w_dynamic) * p_xgb
    y_pred = (p_ensemble >= 0.5).astype(int) # Fixed threshold of 0.5

    return p_ensemble, y_pred

print("Defined predict_ensemble_dynamic_final function.")

"""**Reasoning**:
Now that the `predict_ensemble_dynamic_final` function is defined, I will use it to generate predictions on the `test.parquet` dataset and create the `submission.csv` file as required by the task.


"""

p_test_dynamic, y_test_dynamic = predict_ensemble_dynamic_final(test["code"].tolist())

# Attach predictions to the test DataFrame
test_submission = test.copy()
test_submission["label"] = y_test_dynamic.astype(int)

# Save exactly in required format
test_submission[["ID", "label"]].to_csv("submission_dynamic.csv", index=False)

print("Generated submission_dynamic.csv with dynamic ensemble predictions.")